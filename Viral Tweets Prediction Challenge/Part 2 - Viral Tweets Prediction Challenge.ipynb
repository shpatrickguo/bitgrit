{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6bcf83f-9028-4800-9c13-73b52e9df193",
   "metadata": {},
   "source": [
    "# Viral Tweets Prediction Challenge\n",
    "Develop a machine learning model to predict the virality level of each tweet based on attributes such as tweet content, media attached to the tweet, and date/time published."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737dbf65-ae41-43cc-9789-14740cf77f14",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86d61f5-34b3-4e15-a8d4-8c3830d12017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV \n",
    "\n",
    "#building models\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import timeit\n",
    "import math \n",
    "import collections \n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132b1dc1-1693-4772-8763-e0876d57471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes the minimum and the maximum of each column and changes the data type to what is optimal for the column.\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be6fd5-b807-43ee-acda-1851218646a0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c89c61-6cad-43e7-9fb0-895acb82b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#final_df = pd.read_csv(\"s3://daanmatchdatafiles/bitgrit/final_df.csv\")\n",
    "#p_final_df = pd.read_csv(\"s3://daanmatchdatafiles/bitgrit/p_final_df.csv\")\n",
    "final_df = reduce_mem_usage(pd.read_csv(\"final_df.csv\"))\n",
    "p_final_df = reduce_mem_usage(pd.read_csv(\"p_final_df.csv\"))\n",
    "print(\"Shape of train set: \",train.shape)\n",
    "print(\"Shape of test set: \",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b56ca0-b420-4acb-bc1d-822516bb2ec3",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cfb4e03-76d7-48ed-a3f7-4b5e6c3ddf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape  (20737, 2944)\n",
      "Test set shape  (8888, 2944)\n"
     ]
    }
   ],
   "source": [
    "X = final_df.drop(['virality', 'tweet_user_id', 'tweet_id', 'user_id'], axis=1)\n",
    "y = final_df['virality']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "print('Training set shape ', X_train.shape)\n",
    "print('Test set shape ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346aeede-1dd0-442e-84c6-83d0db032679",
   "metadata": {},
   "source": [
    "# Light GBM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb461cf7-c80b-4bb1-9a4a-098e5cb6a001",
   "metadata": {},
   "source": [
    "Prepare a Baysian Optimization function to find optimal parameters for Light GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "790b156c-5481-4484-837a-d0ed7f3d5187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6,n_estimators=10000, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample):\n",
    "        params = {'application':'binary', 'metric':'auc'}\n",
    "        params['learning_rate'] = max(min(learning_rate, 1), 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['max_bin'] = int(round(max_depth))\n",
    "        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "        \n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "     \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.01, 1.0),\n",
    "                                            'num_leaves': (24, 80),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 30),\n",
    "                                            'max_bin':(20,90),\n",
    "                                            'min_data_in_leaf': (20, 80),\n",
    "                                            'min_sum_hessian_in_leaf':(0,100),\n",
    "                                           'subsample': (0.01, 1.0)}, random_state=200)\n",
    "\n",
    "    \n",
    "    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n",
    "    \n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    model_auc=[]\n",
    "    for model in range(len( lgbBO.res)):\n",
    "        model_auc.append(lgbBO.res[model]['target'])\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6,n_estimators=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12498d-5c04-441a-9cc3-c2de57756f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\n",
    "opt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\n",
    "opt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf']))\n",
    "opt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\n",
    "opt_params[1]['objective']='binary'\n",
    "opt_params[1]['metric']='auc'\n",
    "opt_params[1]['is_unbalance']=True\n",
    "opt_params[1]['boost_from_average']=False\n",
    "opt_params=opt_params[1]\n",
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c7995dc-2e36-47b8-8ad7-10d6efcf924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.003, max_bin=200, max_depth=10, num_leaves=150)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(**params)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c664880-f372-4e21-a2c1-d3e73440fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6cf81d-2b9a-4323-bd59-9c9d88bb4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('roc_auc score: {0:0.4f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc623b06-5f84-4d0f-8a98-d11bd3bd5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,X.columns)), columns=['Value','Feature'])\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:10], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08234147-b3d0-4864-b8de-c3d7945af1ac",
   "metadata": {},
   "source": [
    "# Fit model to Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd960310-31d5-4dec-b710-3a225c6486d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = p_final_df.drop(['tweet_user_id', 'tweet_id', 'user_id'], axis=1)\n",
    "\n",
    "solution = clf.predict(X)\n",
    "solution_df = pd.concat([p_final_df[['tweet_id']], pd.DataFrame(solution, columns = ['virality'])], axis=1)\n",
    "solution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b63271-0116-43d8-9cef-3837c1d3a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution_df.to_csv('solution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
