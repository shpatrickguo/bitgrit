{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6bcf83f-9028-4800-9c13-73b52e9df193",
   "metadata": {},
   "source": [
    "# Viral Tweets Prediction Challenge\n",
    "Develop a machine learning model to predict the virality level of each tweet based on attributes such as tweet content, media attached to the tweet, and date/time published."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737dbf65-ae41-43cc-9789-14740cf77f14",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86d61f5-34b3-4e15-a8d4-8c3830d12017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import collections \n",
    "import time\n",
    "import timeit\n",
    "from datetime import datetime \n",
    "import warnings\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#building models\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132b1dc1-1693-4772-8763-e0876d57471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function takes the minimum and the maximum of each column and changes the data type to what is optimal for the column.\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be6fd5-b807-43ee-acda-1851218646a0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c89c61-6cad-43e7-9fb0-895acb82b98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#final_df = reduce_mem_usage(pd.read_csv(\"s3://daanmatchdatafiles/bitgrit/final_df.csv\"))\n",
    "#p_final_df = reduce_mem_usage(pd.read_csv(\"s3://daanmatchdatafiles/bitgrit/p_final_df.csv\"))\n",
    "final_df = reduce_mem_usage(pd.read_csv(\"final_df.csv\"))\n",
    "p_final_df = reduce_mem_usage(pd.read_csv(\"p_final_df.csv\"))\n",
    "print(\"Shape of train set: \", final_df.shape)\n",
    "print(\"Shape of test set: \", p_final_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b56ca0-b420-4acb-bc1d-822516bb2ec3",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfb4e03-76d7-48ed-a3f7-4b5e6c3ddf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape  (20737, 2944)\n",
      "Test set shape  (8888, 2944)\n"
     ]
    }
   ],
   "source": [
    "X = final_df.drop(['virality', 'tweet_user_id', 'tweet_id', 'user_id'], axis=1)\n",
    "y = final_df['virality']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "print('Training set shape ', X_train.shape)\n",
    "print('Test set shape ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346aeede-1dd0-442e-84c6-83d0db032679",
   "metadata": {},
   "source": [
    "# Tune parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb461cf7-c80b-4bb1-9a4a-098e5cb6a001",
   "metadata": {},
   "source": [
    "Prepare a Baysian Optimization function to find optimal parameters for Light GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca84d6fb-5fbc-4aaa-8d5b-1f2bb527c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "    params = {'application':'binary','num_iterations':4000, 'learning_rate':0.05, 'early_stopping_round':100, 'metric':'auc'}\n",
    "    params[\"num_leaves\"] = round(num_leaves)\n",
    "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "    params['max_depth'] = round(max_depth)\n",
    "    params['lambda_l1'] = max(lambda_l1, 0)\n",
    "    params['lambda_l2'] = max(lambda_l2, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "    return max(cv_result['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a016b90-71b5-49af-91ff-05e0144deb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the range for each parameter¶\n",
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                        'feature_fraction': (0.1, 0.9),\n",
    "                                        'bagging_fraction': (0.8, 1),\n",
    "                                        'max_depth': (5, 8.99),\n",
    "                                        'lambda_l1': (0, 5),\n",
    "                                        'lambda_l2': (0, 3),\n",
    "                                        'min_split_gain': (0.001, 0.1),\n",
    "                                        'min_child_weight': (5, 50)}, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9db3c-3a3a-4195-850b-0f3823b71e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO.maximize(init_points=init_round, n_iter=opt_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b133de-7fc2-40e2-9ce6-3dd03e32dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c7995dc-2e36-47b8-8ad7-10d6efcf924c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.003, max_bin=200, max_depth=10, num_leaves=150)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(**opt_params)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c664880-f372-4e21-a2c1-d3e73440fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6cf81d-2b9a-4323-bd59-9c9d88bb4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Base accuracy 66.45%\n",
    "print('Accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('roc_auc score: {0:0.4f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc623b06-5f84-4d0f-8a98-d11bd3bd5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,X.columns)), columns=['Value','Feature'])\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:10], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08234147-b3d0-4864-b8de-c3d7945af1ac",
   "metadata": {},
   "source": [
    "# Fit model to Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd960310-31d5-4dec-b710-3a225c6486d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = p_final_df.drop(['tweet_user_id', 'tweet_id', 'user_id'], axis=1)\n",
    "\n",
    "solution = clf.predict(X)\n",
    "solution_df = pd.concat([p_final_df[['tweet_id']], pd.DataFrame(solution, columns = ['virality'])], axis=1)\n",
    "solution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b63271-0116-43d8-9cef-3837c1d3a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution_df.to_csv('solution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
